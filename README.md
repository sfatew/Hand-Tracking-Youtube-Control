# Hand-Tracking-Computer-Control

This project leverages computer vision techniques to track hand motion and control a computer interface in a similar manner to a touchpad.

## Overview

The goal of this project is to develop a system that allows for hand gesture recognition using multi-scale spatial-temporal convolutional neural networks. The system tracks hand movements and translates them into computer commands, offering a hands-free way to interact with digital devices.

## Paper Reference

### Multi-scale Spatialâ€“Temporal Convolutional Neural Network for Skeleton-based Action Recognition  
May 2023. *Pattern Analysis and Applications*<br>
DOI: [10.1007/s10044-023-01156-w](https://doi.org/10.1007/s10044-023-01156-w)

## Dataset

The dataset used for training the model is MSSTNET, which includes various skeleton-based data that helps in recognizing hand gestures.

### MSSTNET Train Dataset  
You can download the dataset from Kaggle:  
[MSSTNET Dataset on Kaggle](https://www.kaggle.com/datasets/joemum/msstnetdataset)

## Model

The model used for recognizing hand gestures is based on MSSTNET and can be accessed from Kaggle as well.

### MSSTNET Model  
You can download or explore the MSSTNET model from:  
[MSSTNET Model on Kaggle](https://www.kaggle.com/models/joemum/mssnet_model)

### STMEM+ResNet Model
(https://drive.google.com/file/d/18S8gpzzmWoBoKfEFyigjb8G8pAp7gA_g/view?usp=sharing)


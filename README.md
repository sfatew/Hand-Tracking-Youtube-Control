# Hand-Tracking-Computer-Control

This project leverages computer vision techniques to track hand motion and control a computer interface in a similar manner to a touchpad.

## Overview

The goal of this project is to develop a system that allows for hand gesture recognition using DSCNet. The system tracks hand movements and translates them into computer commands, offering a hands-free way to interact with digital devices.

## Paper Reference

### A Dense-Sparse Complementary Network for Human Action Recognition based on RGB and Skeleton Modalities
(https://www.sciencedirect.com/science/article/abs/pii/S0957417423035637)

### Multi-scale Spatialâ€“Temporal Convolutional Neural Network for Skeleton-based Action Recognition  
May 2023. *Pattern Analysis and Applications*<br>
DOI: [10.1007/s10044-023-01156-w](https://doi.org/10.1007/s10044-023-01156-w)

## Dataset

The dataset used for training the model is Jester, which includes various video data that helps in recognizing hand action.

### MSSTNET Train Dataset  
You can download the dataset from Kaggle:  
[20bn-jester Dataset on Kaggle](https://www.kaggle.com/datasets/toxicmender/20bn-jester)

## Model

The models used for recognizing hand gestures can be access via thesse link.
To use these model, simnply create a model folder in the respected directory and put them in there

### MSSTNET Model  
You can download or explore the MSSTNET model from:  
[MSSTNET Model on Kaggle](https://www.kaggle.com/models/joemum/mssnet_model)

### STMEM+ResNet Model
[STMEM+ResNet Model](https://drive.google.com/file/d/18S8gpzzmWoBoKfEFyigjb8G8pAp7gA_g/view?usp=sharing)


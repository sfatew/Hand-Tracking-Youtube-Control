{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:23.993177Z",
     "iopub.status.busy": "2025-05-07T17:26:23.992854Z",
     "iopub.status.idle": "2025-05-07T17:26:27.033305Z",
     "shell.execute_reply": "2025-05-07T17:26:27.032198Z",
     "shell.execute_reply.started": "2025-05-07T17:26:23.993150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install -U albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:27.035378Z",
     "iopub.status.busy": "2025-05-07T17:26:27.035139Z",
     "iopub.status.idle": "2025-05-07T17:26:27.063587Z",
     "shell.execute_reply": "2025-05-07T17:26:27.063049Z",
     "shell.execute_reply.started": "2025-05-07T17:26:27.035358Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division,print_function, unicode_literals\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Flatten, Dropout, BatchNormalization, AveragePooling3D\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.layers import Add\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu3D(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv3d(**conv_params):\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\",\"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\",\n",
    "                                                l2(1e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv3D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, kernel_initializer=kernel_initializer,\n",
    "                      padding=padding,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut3d(input, residual):\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "\n",
    "    stride_dim1 = input_shape[DIM1_AXIS] // residual_shape[DIM1_AXIS]\n",
    "    stride_dim2 = input_shape[DIM2_AXIS] // residual_shape[DIM2_AXIS]\n",
    "    stride_dim3 = input_shape[DIM3_AXIS] // residual_shape[DIM3_AXIS]\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_dim1 > 1 or stride_dim2 > 1 or stride_dim3 > 1 or not equal_channels:\n",
    "        shortcut = Conv3D(\n",
    "            filters=residual_shape[CHANNEL_AXIS],\n",
    "            kernel_size=(1, 1, 1),\n",
    "            strides=(stride_dim1, stride_dim2, stride_dim3),\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            padding=\"same\",\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "        )(input)\n",
    "\n",
    "    return Add()([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block3d(block_function, filters, kernel_regularizer, repetitions, is_first_layer=False):\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            strides = (1, 1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                strides = (2, 2, 2)\n",
    "            input = block_function(filters=filters, strides=strides,\n",
    "                                   kernel_regularizer=kernel_regularizer,\n",
    "                                   is_first_block_of_first_layer=(\n",
    "                                       is_first_layer and i == 0)\n",
    "                                   )(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "                is_first_block_of_first_layer=False):\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n",
    "                           strides=strides, padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=kernel_regularizer\n",
    "                           )(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv3d(filters=filters,\n",
    "                                    kernel_size=(3, 3, 3),\n",
    "                                    strides=strides,\n",
    "                                    kernel_regularizer=kernel_regularizer\n",
    "                                    )(input)\n",
    "\n",
    "        residual = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv1)\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, strides=(1, 1, 1), kernel_regularizer=l2(1e-4),\n",
    "               is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 X 3 convolution blocks. Extended from raghakot's 2D impl.\"\"\"\n",
    "    def f(input):\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n",
    "                              strides=strides, padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=kernel_regularizer\n",
    "                              )(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv3d(filters=filters, kernel_size=(1, 1, 1),\n",
    "                                       strides=strides,\n",
    "                                       kernel_regularizer=kernel_regularizer\n",
    "                                       )(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv3d(filters=filters, kernel_size=(3, 3, 3),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_1_1)\n",
    "        residual = _bn_relu_conv3d(filters=filters * 4, kernel_size=(1, 1, 1),\n",
    "                                   kernel_regularizer=kernel_regularizer\n",
    "                                   )(conv_3_3)\n",
    "\n",
    "        return _shortcut3d(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_data_format():\n",
    "    global DIM1_AXIS\n",
    "    global DIM2_AXIS\n",
    "    global DIM3_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        DIM1_AXIS = 1\n",
    "        DIM2_AXIS = 2\n",
    "        DIM3_AXIS = 3\n",
    "        CHANNEL_AXIS = 4\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        DIM1_AXIS = 2\n",
    "        DIM2_AXIS = 3\n",
    "        DIM3_AXIS = 4\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class Resnet3DBuilder(object):\n",
    "    \"\"\"ResNet3D.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions, reg_factor, drop_rate=0):\n",
    "     \n",
    "        _handle_data_format()\n",
    "        if len(input_shape) != 4:\n",
    "            raise ValueError(\"Input shape should be a tuple \"\n",
    "                             \"(conv_dim1, conv_dim2, conv_dim3, channels) \"\n",
    "                             \"for tensorflow as backend or \"\n",
    "                             \"(channels, conv_dim1, conv_dim2, conv_dim3) \"\n",
    "                             \"for theano as backend\")\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "        input = Input(shape=input_shape)\n",
    "        # first conv\n",
    "        conv1 = _conv_bn_relu3D(filters=64, kernel_size=(7, 7, 7),\n",
    "                                strides=(2, 2, 2),\n",
    "                                kernel_regularizer=l2(reg_factor)\n",
    "                                )(input)\n",
    "        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2),\n",
    "                             padding=\"same\")(conv1)\n",
    "\n",
    "        # repeat blocks\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block3d(block_fn, filters=filters,\n",
    "                                      kernel_regularizer=l2(reg_factor),\n",
    "                                      repetitions=r, is_first_layer=(i == 0)\n",
    "                                      )(block)\n",
    "            filters *= 2\n",
    "            block = Dropout(drop_rate)(block)\n",
    "\n",
    "        # last activation\n",
    "        block_output = _bn_relu(block)\n",
    "\n",
    "        # average poll and classification\n",
    "        pool2 = AveragePooling3D(pool_size=(\n",
    "                                            K.int_shape(block)[DIM1_AXIS],\n",
    "                                            K.int_shape(block)[DIM2_AXIS],\n",
    "                                            K.int_shape(block)[DIM3_AXIS]),strides=(1, 1, 1))(block_output)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        if num_outputs > 1:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"softmax\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "        else:\n",
    "            dense = Dense(units=num_outputs,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          activation=\"sigmoid\",\n",
    "                          kernel_regularizer=l2(reg_factor))(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs, reg_factor=1e-4, drop_rate=0):\n",
    "        \"\"\"Build resnet 101.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 23, 3], reg_factor=reg_factor, drop_rate=drop_rate)\n",
    "    \n",
    "    def build_resnet_50(input_shape, num_outputs, reg_factor=1e-4, drop_rate=0):\n",
    "        \"\"\"Build resnet 50.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, bottleneck,\n",
    "                                     [3, 4, 6, 3], reg_factor=reg_factor, drop_rate=drop_rate)\n",
    "        \n",
    "    def build_resnet_18(input_shape, num_outputs, reg_factor=1e-4, drop_rate=0):\n",
    "        \"\"\"Build resnet 18.\"\"\"\n",
    "        return Resnet3DBuilder.build(input_shape, num_outputs, basic_block,\n",
    "                                     [2, 2, 2, 2], reg_factor=reg_factor, drop_rate=drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:27.064471Z",
     "iopub.status.busy": "2025-05-07T17:26:27.064262Z",
     "iopub.status.idle": "2025-05-07T17:26:32.468277Z",
     "shell.execute_reply": "2025-05-07T17:26:32.467596Z",
     "shell.execute_reply.started": "2025-05-07T17:26:27.064455Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class STMEM(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    A custom TensorFlow model for spatiotemporal modeling using frame differences\n",
    "    and a prebuilt 3D ResNet.\n",
    "\n",
    "    Args:\n",
    "        num_segments (int): Number of segments in the video.\n",
    "        new_length (int): Number of frames per segment.\n",
    "        prebuilt_resnet (tf.keras.Model): Prebuilt 3D ResNet model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_segments, new_length, prebuilt_resnet, img_size = (224,224)):\n",
    "        super(STMEM, self).__init__()\n",
    "        self.num_segments = num_segments\n",
    "        self.new_length = int(new_length)\n",
    "        self.height, self.width = img_size\n",
    "\n",
    "        # Layers from the STMEM model\n",
    "        self.m1 = layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding='same',\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        )\n",
    "\n",
    "        self.m2 = layers.Conv2D(\n",
    "            filters=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding='same',\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        )\n",
    "\n",
    "        self.sigmoid = tf.keras.activations.sigmoid\n",
    "\n",
    "        # The prebuilt 3D ResNet model\n",
    "        self.resnet = prebuilt_resnet  # This is passed as a parameter\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        if len(input_tensor.shape) != 5:\n",
    "            raise ValueError(\"Input tensor must have shape (B, D, H, W, C)\")\n",
    "        \n",
    "        # input_tensor: (B, D, H, W, C)\n",
    "        B = tf.shape(input_tensor)[0]\n",
    "        D = input_tensor.shape[1]  # Should be num_segments * new_length\n",
    "        H = input_tensor.shape[2]\n",
    "        W = input_tensor.shape[3]\n",
    "        C = input_tensor.shape[4]\n",
    "\n",
    "        # Reshape from (B, D, H, W, C) → (B, SLC, H, W)\n",
    "        # transpose to (B, C, D, H, W)\n",
    "        input_tensor = tf.transpose(input_tensor, [0, 4, 1, 2, 3])\n",
    "\n",
    "        # reshape to (B, C * D, H, W)\n",
    "        input_tensor = tf.reshape(input_tensor, [B, C * D, H, W])\n",
    "        \n",
    "        #shape: (B, SLC, H, W)\n",
    "        SLC = input_tensor.shape[1]  # should be num_segments * new_length * 3\n",
    "\n",
    "        # Transpose to (B, H, W, SLC)\n",
    "        input_tensor = tf.transpose(input_tensor, [0, 2, 3, 1])  # (B, H, W, SLC)\n",
    "        input_tensor = tf.reshape(input_tensor, [B * self.num_segments, self.height, self.width, self.new_length * 3])\n",
    "\n",
    "        # Frame difference\n",
    "        frame_diff = input_tensor[:, :, :, 3:] - input_tensor[:, :, :, : (self.new_length - 1) * 3]\n",
    "\n",
    "        input_and_frame_diff = tf.concat([input_tensor, frame_diff], axis=-1)\n",
    "        input_and_frame_diff = self.m1(input_and_frame_diff)\n",
    "\n",
    "        # Process frame difference\n",
    "        frame_diff = tf.reshape(frame_diff, [B * self.num_segments, self.height, self.width, self.new_length - 1, 3])\n",
    "        frame_diff = tf.reduce_max(frame_diff, axis=3)  # max over length axis\n",
    "        frame_diff = self.m2(frame_diff)\n",
    "        frame_diff = self.sigmoid(frame_diff)\n",
    "\n",
    "        output = frame_diff * input_and_frame_diff #(B * num_segments, 224, 224, 3)\n",
    "\n",
    "        # Reshape back to (B, num_segments, H, W, C)\n",
    "        output = tf.reshape(output, [B, self.num_segments, self.height, self.width, 3])\n",
    "\n",
    "        # Now pass the output through the prebuilt 3D ResNet\n",
    "        resnet_output = self.resnet(output)  # Output from ResNet\n",
    "        \n",
    "        #return tf.cast(resnet_output, tf.float32)\n",
    "        return resnet_output\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example input: shape (B, SLC, H, W) → (4, 90, 224, 224)\n",
    "    a = tf.convert_to_tensor(np.random.rand(2, 36, 224, 224, 3).astype(np.float32))\n",
    "    \n",
    "    resnet = Resnet3DBuilder.build_resnet_50(\n",
    "        input_shape=(6, 224, 224, 3),  # frame, 112x112, 3 channels (RGB)\n",
    "        num_outputs=18)\n",
    "\n",
    "    model = STMEM(num_segments=6, new_length=6, prebuilt_resnet=resnet)\n",
    "    out = model(a)\n",
    "    print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:32.470444Z",
     "iopub.status.busy": "2025-05-07T17:26:32.470221Z",
     "iopub.status.idle": "2025-05-07T17:26:32.475458Z",
     "shell.execute_reply": "2025-05-07T17:26:32.474846Z",
     "shell.execute_reply.started": "2025-05-07T17:26:32.470426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data frame processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:32.476381Z",
     "iopub.status.busy": "2025-05-07T17:26:32.476155Z",
     "iopub.status.idle": "2025-05-07T17:26:37.234431Z",
     "shell.execute_reply": "2025-05-07T17:26:37.233744Z",
     "shell.execute_reply.started": "2025-05-07T17:26:32.476362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import ReplayCompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.235521Z",
     "iopub.status.busy": "2025-05-07T17:26:37.235076Z",
     "iopub.status.idle": "2025-05-07T17:26:37.239293Z",
     "shell.execute_reply": "2025-05-07T17:26:37.238493Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.235501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = \"/kaggle/input/20-bnjester-csv-files/Train.csv\"\n",
    "VAL_DATA_DIR = \"/kaggle/input/20-bnjester-csv-files/Validation.csv\"\n",
    "Cropped_TRAIN_DIR = \"/kaggle/input/hand-cropped-20jester-train-dataset/Cropped_Train_Data\"\n",
    "Cropped_VAL_DIR = \"/kaggle/input/hand-cropped-20jester-validation-dataset/Cropped_Validation_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.240357Z",
     "iopub.status.busy": "2025-05-07T17:26:37.240077Z",
     "iopub.status.idle": "2025-05-07T17:26:37.282783Z",
     "shell.execute_reply": "2025-05-07T17:26:37.282058Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.240332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.283759Z",
     "iopub.status.busy": "2025-05-07T17:26:37.283566Z",
     "iopub.status.idle": "2025-05-07T17:26:37.301300Z",
     "shell.execute_reply": "2025-05-07T17:26:37.300568Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.283734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([[\"Doing other things\"], [\"No gesture\"],\n",
    "         [\"Rolling Hand Backward\"], [\"Rolling Hand Forward\"],\n",
    "         [\"Shaking Hand\"], \n",
    "         [\"Sliding Two Fingers Down\"], [\"Sliding Two Fingers Left\"], [\"Sliding Two Fingers Right\"], [\"Sliding Two Fingers Up\"], \n",
    "         [\"Stop Sign\"], \n",
    "         [\"Swiping Down\"], [\"Swiping Left\"], [\"Swiping Right\"], [\"Swiping Up\"],\n",
    "         [\"Thumb Down\"], [\"Thumb Up\"],\n",
    "         [\"Turning Hand Clockwise\"], [\"Turning Hand Counterclockwise\"]])\n",
    "\n",
    "\n",
    "label_encoder.fit(labels) # fit encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.302135Z",
     "iopub.status.busy": "2025-05-07T17:26:37.301925Z",
     "iopub.status.idle": "2025-05-07T17:26:37.679780Z",
     "shell.execute_reply": "2025-05-07T17:26:37.679211Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.302119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_video_id_ls = list(map(int, os.listdir(Cropped_TRAIN_DIR)))\n",
    "val_video_id_ls = list(map(int, os.listdir(Cropped_VAL_DIR)))\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_DIR)\n",
    "val_df = pd.read_csv(VAL_DATA_DIR)\n",
    "\n",
    "sort_train_df = train_df[train_df[\"video_id\"].isin(train_video_id_ls)] # sorting only the used data\n",
    "sort_val_df = val_df[val_df[\"video_id\"].isin(val_video_id_ls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.682572Z",
     "iopub.status.busy": "2025-05-07T17:26:37.682355Z",
     "iopub.status.idle": "2025-05-07T17:26:37.687220Z",
     "shell.execute_reply": "2025-05-07T17:26:37.686394Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.682556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"train_df len: \", len(train_df))\n",
    "print(\"sort_train_df len: \", len(sort_train_df))\n",
    "print(\"val_df len: \", len(val_df))\n",
    "print(\"sort_val_df len: \", len(sort_val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:26:37.688872Z",
     "iopub.status.busy": "2025-05-07T17:26:37.688497Z",
     "iopub.status.idle": "2025-05-07T17:26:37.699587Z",
     "shell.execute_reply": "2025-05-07T17:26:37.698791Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.688840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:38:10.056072Z",
     "iopub.status.busy": "2025-05-07T17:38:10.055248Z",
     "iopub.status.idle": "2025-05-07T17:38:10.060356Z",
     "shell.execute_reply": "2025-05-07T17:38:10.059652Z",
     "shell.execute_reply.started": "2025-05-07T17:38:10.056045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def augmentation(img, input_shape):\n",
    "    \"\"\"Augmentation function for albumentations.\"\"\"\n",
    "    #IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "    #IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "    transform = ReplayCompose([\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Resize(height=input_shape[0], width=input_shape[1]),\n",
    "    ])\n",
    "\n",
    "    aug = transform(image=img)\n",
    "\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:38:13.632139Z",
     "iopub.status.busy": "2025-05-07T17:38:13.631543Z",
     "iopub.status.idle": "2025-05-07T17:38:13.640735Z",
     "shell.execute_reply": "2025-05-07T17:38:13.639954Z",
     "shell.execute_reply.started": "2025-05-07T17:38:13.632115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VideoDataset(Sequence):\n",
    "    def __init__(self, usage, data_frame, video_dir, batch_size, input_shape, shuffle=True):\n",
    "        self.usage = usage\n",
    "        self.data = data_frame\n",
    "        self.video_dir = video_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape  # (D, H, W, C)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.data.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        X = np.zeros((len(batch_data), *self.input_shape), dtype=np.float32)\n",
    "        y = []\n",
    "\n",
    "        for i, row in enumerate(batch_data.itertuples()):\n",
    "            video_id = row.video_id\n",
    "            label = row.label\n",
    "            folder = os.path.join(self.video_dir, str(video_id))\n",
    "\n",
    "            frames = []\n",
    "            replay = None\n",
    "            \n",
    "            for j in range(1, 37):\n",
    "                img_path = os.path.join(folder, f\"{j:05d}.jpg\")\n",
    "                img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "                if self.usage == \"train\":\n",
    "                    if replay is None:\n",
    "                        aug = augmentation(img=img, input_shape=(self.input_shape[1], self.input_shape[2]))\n",
    "                        replay = aug[\"replay\"]\n",
    "                \n",
    "                    aug_img = A.ReplayCompose.replay(replay, image=img)[\"image\"]\n",
    "                    aug_img = aug_img.astype(np.float32) / 255.0\n",
    "                    frames.append(aug_img)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (self.input_shape[2], self.input_shape[1]))\n",
    "                    img = img.astype(np.float32) / 255.0\n",
    "                    frames.append(img)\n",
    "\n",
    "            X[i] = np.stack(frames, axis=0)  # (D, H, W, C)\n",
    "            #print(X[i].shape)\n",
    "\n",
    "            y.append([label])\n",
    "        \n",
    "        y = label_encoder.transform(y)#to_categorical(y, num_classes=self.num_classes)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:38:16.726282Z",
     "iopub.status.busy": "2025-05-07T17:38:16.725945Z",
     "iopub.status.idle": "2025-05-07T17:38:16.739299Z",
     "shell.execute_reply": "2025-05-07T17:38:16.738408Z",
     "shell.execute_reply.started": "2025-05-07T17:38:16.726259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# VIDEO Dataset\n",
    "train_dataset = VideoDataset(\n",
    "    usage = \"train\",\n",
    "    data_frame= sort_train_df,          # data frame đọc từ csv file\n",
    "    video_dir=Cropped_TRAIN_DIR,   # đường dẫn tới folder chứa các video dạng frame\n",
    "    batch_size=batch_size,                   # mỗi batch lấy 4 video\n",
    "    input_shape=(36, 128, 128, 3),   #  frame, size 128x128, 3 kênh màu\n",
    "    shuffle=True                    # có muốn shuffle dữ liệu mỗi epoch không\n",
    ")\n",
    "\n",
    "val_dataset = VideoDataset(\n",
    "    usage = \"val\",\n",
    "    data_frame= sort_val_df,          # data frame đọc từ csv file\n",
    "    video_dir=Cropped_VAL_DIR,   # đường dẫn tới folder chứa các video dạng frame\n",
    "    batch_size=batch_size,                   # mỗi batch lấy 4 video\n",
    "    input_shape=(36, 128, 128, 3),   #  frame, size 128x128, 3 kênh màu\n",
    "    shuffle=True                    # có muốn shuffle dữ liệu mỗi epoch không\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:39:41.700883Z",
     "iopub.status.busy": "2025-05-07T17:39:41.700359Z",
     "iopub.status.idle": "2025-05-07T17:39:44.030191Z",
     "shell.execute_reply": "2025-05-07T17:39:44.029621Z",
     "shell.execute_reply.started": "2025-05-07T17:39:41.700861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Exam the work of dataset\n",
    "X_batch, y_batch = train_dataset[0]\n",
    "print(np.max(X_batch))\n",
    "print(np.min(X_batch))\n",
    "print(y_batch.shape)\n",
    "\n",
    "#print(X_batch[0])\n",
    "print(y_batch[0])\n",
    "\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.852947Z",
     "iopub.status.idle": "2025-05-07T17:26:37.853187Z",
     "shell.execute_reply": "2025-05-07T17:26:37.853090Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.853079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "\n",
    "def generator(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        yield dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.854507Z",
     "iopub.status.idle": "2025-05-07T17:26:37.854792Z",
     "shell.execute_reply": "2025-05-07T17:26:37.854643Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.854632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.855835Z",
     "iopub.status.idle": "2025-05-07T17:26:37.856066Z",
     "shell.execute_reply": "2025-05-07T17:26:37.855949Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.855940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "#from tensorflow.keras import mixed_precision\n",
    "#mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.856604Z",
     "iopub.status.idle": "2025-05-07T17:26:37.857070Z",
     "shell.execute_reply": "2025-05-07T17:26:37.856940Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.856928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PROJECT = \"HandActionReg\"\n",
    "RESUME = \"allow\"\n",
    "WANDB_KEY = \"d9d14819dddd8a35a353b5c0b087e0f60d717140\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.857744Z",
     "iopub.status.idle": "2025-05-07T17:26:37.857938Z",
     "shell.execute_reply": "2025-05-07T17:26:37.857855Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.857847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(\n",
    "    key = WANDB_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.858974Z",
     "iopub.status.idle": "2025-05-07T17:26:37.859306Z",
     "shell.execute_reply": "2025-05-07T17:26:37.859153Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.859138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.860165Z",
     "iopub.status.idle": "2025-05-07T17:26:37.860441Z",
     "shell.execute_reply": "2025-05-07T17:26:37.860321Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.860306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Khởi tạo MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.861639Z",
     "iopub.status.idle": "2025-05-07T17:26:37.861964Z",
     "shell.execute_reply": "2025-05-07T17:26:37.861826Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.861796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    print(\"Number of GPUs: \", strategy.num_replicas_in_sync)\n",
    "    print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    num_segments = 6\n",
    "    INPUT_DEPTH = 36\n",
    "\n",
    "    resnet = Resnet3DBuilder.build_resnet_50(\n",
    "        input_shape=(num_segments, 128, 128, 3),  # frame, 128x128, 3 channels (RGB)\n",
    "        num_outputs=18)\n",
    "    \n",
    "\n",
    "    model = STMEM(\n",
    "        num_segments=num_segments,\n",
    "        new_length=INPUT_DEPTH/num_segments,\n",
    "        prebuilt_resnet=resnet,\n",
    "        img_size = (128,128)\n",
    "    )\n",
    "\n",
    "    # Biên dịch mô hình\n",
    "    model.compile(optimizer=Adam(learning_rate = learning_rate, weight_decay = 1e-6, clipnorm=1.0),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.863280Z",
     "iopub.status.idle": "2025-05-07T17:26:37.863570Z",
     "shell.execute_reply": "2025-05-07T17:26:37.863422Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.863406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.864533Z",
     "iopub.status.idle": "2025-05-07T17:26:37.864810Z",
     "shell.execute_reply": "2025-05-07T17:26:37.864692Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.864680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.865903Z",
     "iopub.status.idle": "2025-05-07T17:26:37.866248Z",
     "shell.execute_reply": "2025-05-07T17:26:37.866070Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.866053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#BUFFERED_BATCHES = 300\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "gen_train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_dataset), \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, INPUT_DEPTH, 128, 128, 3), dtype=tf.float32),  # X.shape\n",
    "        tf.TensorSpec(shape=(None, 18), dtype=tf.float32)  # y.shape\n",
    "    )\n",
    ").prefetch(AUTOTUNE)\n",
    "\n",
    "gen_val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(val_dataset), \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, INPUT_DEPTH, 128, 128, 3), dtype=tf.float32),  # X.shape\n",
    "        tf.TensorSpec(shape=(None, 18), dtype=tf.float32)  # y.shape\n",
    "    )\n",
    ").prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.867286Z",
     "iopub.status.idle": "2025-05-07T17:26:37.867581Z",
     "shell.execute_reply": "2025-05-07T17:26:37.867446Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.867434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN \n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=7,            # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,          # reduce LR by this factor\n",
    "    patience=5,          # wait this many epochs\n",
    "    min_lr=1e-6          # lower bound\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='/kaggle/working/STMEM_3D_RestNet50.keras',        # Filepath to save the model\n",
    "    monitor='val_loss',              # Monitor validation loss\n",
    "    save_best_only=True,             # Only save when val_loss improves\n",
    "    save_weights_only=False,         # Save full model (set to True to save only weights)\n",
    "    mode='min',                      # 'min' means lower val_loss is better\n",
    "    verbose=1                        # Logs when the model is saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.868794Z",
     "iopub.status.idle": "2025-05-07T17:26:37.869124Z",
     "shell.execute_reply": "2025-05-07T17:26:37.868958Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.868943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=PROJECT,\n",
    "    resume=RESUME,\n",
    "    name=\"STMEM_hand_init\",\n",
    "    config={\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"epochs\": epochs,\n",
    "         \"batch_size\": batch_size,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-07T17:26:37.870207Z",
     "iopub.status.idle": "2025-05-07T17:26:37.870477Z",
     "shell.execute_reply": "2025-05-07T17:26:37.870338Z",
     "shell.execute_reply.started": "2025-05-07T17:26:37.870326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.fit(gen_train_dataset.repeat(), \n",
    "          epochs= epochs, \n",
    "          steps_per_epoch=len(train_dataset), \n",
    "          validation_data=gen_val_dataset, \n",
    "          verbose=1,\n",
    "          callbacks=[\n",
    "                TerminateOnNaN(),\n",
    "                WandbCallback(save_model=False),  # Logs metrics, gradients, and optionally saves the model\n",
    "                early_stop,\n",
    "                reduce_lr,\n",
    "                checkpoint,\n",
    "            ])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7136783,
     "sourceId": 11395349,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7137173,
     "sourceId": 11396014,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7254045,
     "sourceId": 11570522,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "handtracking_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97827c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras  \n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9fac9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"Doing other things\", \"No gesture\", 'Rolling Hand Backward', 'Rolling Hand Forward', 'Shaking Hand', \n",
    "           'Sliding Two Fingers Down', 'Sliding Two Fingers Left', 'Sliding Two Fingers Right', 'Sliding Two Fingers Up',\n",
    "            'Stop Sign', 'Swiping Down','Swiping Left', 'Swiping Right', 'Swiping Up',\n",
    "            'Thumb Down', 'Thumb Up',\n",
    "            'Turning Hand Clockwise', 'Turning Hand Counterclockwise'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eeb9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\Validation.csv\")\n",
    "df.drop(columns = ['format', 'shape', 'frames'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "336f8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['label'].isin(actions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e29b412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Swiping Down</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Swiping Right</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>177</td>\n",
       "      <td>Thumb Down</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>147945</td>\n",
       "      <td>Shaking Hand</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043</th>\n",
       "      <td>147960</td>\n",
       "      <td>Sliding Two Fingers Left</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7044</th>\n",
       "      <td>148032</td>\n",
       "      <td>Doing other things</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>148046</td>\n",
       "      <td>Doing other things</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>148071</td>\n",
       "      <td>Swiping Left</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                     label  label_id\n",
       "1           30              Swiping Down        15\n",
       "2           68              Shaking Hand         9\n",
       "3           77                Thumb Down        19\n",
       "4           96             Swiping Right        17\n",
       "7          177                Thumb Down        19\n",
       "...        ...                       ...       ...\n",
       "7042    147945              Shaking Hand         9\n",
       "7043    147960  Sliding Two Fingers Left        11\n",
       "7044    148032        Doing other things         0\n",
       "7045    148046        Doing other things         0\n",
       "7046    148071              Swiping Left        16\n",
       "\n",
       "[4780 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94825f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, Dense, InputLayer, Activation, GlobalAveragePooling2D, BatchNormalization, ReLU, AveragePooling2D, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b2eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSST_Layer(Layer):\n",
    "    def __init__(self, stride, filter1, filter2, filter3, filter4, filter5, **kwargs):\n",
    "        super(MSST_Layer, self).__init__(**kwargs)\n",
    "        self.stride = stride\n",
    "        self.filters = [filter1, filter2, filter3, filter4, filter5]\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        # Tạo các nhánh\n",
    "        self.branch1 = self._make_branch([(1, 1)], filter1, stride)\n",
    "        self.branch2 = self._make_branch([(1, 1), (3, 3)], [filter1, filter2], stride)\n",
    "        self.branch3 = self._make_branch([(1, 1), (5, 1), (1, 5)], [filter3]*3, stride)\n",
    "        self.branch4 = self._make_branch([(1, 1), (7, 1), (1, 7)], [filter4]*3, stride)\n",
    "        self.branch5 = self._make_branch([(1, 1), (11, 1), (1, 11)], [filter5]*3, stride)\n",
    "\n",
    "    def _make_branch(self, kernel_sizes, filters, first_stride):\n",
    "        layers = []\n",
    "        if isinstance(filters, int):\n",
    "            filters = [filters] * len(kernel_sizes)\n",
    "        for i, (kernel, f) in enumerate(zip(kernel_sizes, filters)):\n",
    "            stride = first_stride if i == 0 else (1, 1)\n",
    "            layers.append(Conv2D(f, kernel_size=kernel, strides=stride, padding='same'))\n",
    "            layers.append(BatchNormalization())\n",
    "            layers.append(ReLU())\n",
    "        return layers\n",
    "\n",
    "    def _apply_branch(self, inputs, branch_layers, training):\n",
    "        x = inputs\n",
    "        for layer in branch_layers:\n",
    "            if isinstance(layer, BatchNormalization):\n",
    "                x = layer(x, training=training)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        b1 = self._apply_branch(inputs, self.branch1, training)\n",
    "        b2 = self._apply_branch(inputs, self.branch2, training)\n",
    "        b3 = self._apply_branch(inputs, self.branch3, training)\n",
    "        b4 = self._apply_branch(inputs, self.branch4, training)\n",
    "        b5 = self._apply_branch(inputs, self.branch5, training)\n",
    "        return self.concat([b1, b2, b3, b4, b5])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MSST_Layer, self).get_config()\n",
    "        keys = ['filter1', 'filter2', 'filter3', 'filter4', 'filter5']\n",
    "        config.update({'stride': self.stride, **{k: v for k, v in zip(keys, self.filters)}})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "573a42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSE_CONNECTIONS = frozenset([(11, 12), (11, 13), (13, 15), (12, 14), (14, 16)])\n",
    "    \n",
    "# Mapping from pose landmark IDs to file landmark IDs\n",
    "poseid2fileid = {12: 0, 14: 1, 16: 2, 11: 3, 13: 4, 15: 5}\n",
    "\n",
    "# Create file connections based on mapped pose IDs\n",
    "POSE_CONNECTIONS_FILE_INDEX = [\n",
    "    (poseid2fileid[a], poseid2fileid[b])\n",
    "    for (a, b) in POSE_CONNECTIONS\n",
    "]\n",
    "\n",
    "\"Connection\" \n",
    "HAND_PALM_CONNECTIONS = ((0, 1), (0, 5), (9, 13), (13, 17), (5, 9), (0, 17))\n",
    "\n",
    "HAND_THUMB_CONNECTIONS = ((1, 2), (2, 3), (3, 4))\n",
    "\n",
    "HAND_INDEX_FINGER_CONNECTIONS = ((5, 6), (6, 7), (7, 8))\n",
    "\n",
    "HAND_MIDDLE_FINGER_CONNECTIONS = ((9, 10), (10, 11), (11, 12))\n",
    "\n",
    "HAND_RING_FINGER_CONNECTIONS = ((13, 14), (14, 15), (15, 16))\n",
    "\n",
    "HAND_PINKY_FINGER_CONNECTIONS = ((17, 18), (18, 19), (19, 20))\n",
    "\n",
    "HAND_CONNECTIONS = frozenset().union(*[\n",
    "    HAND_PALM_CONNECTIONS, HAND_THUMB_CONNECTIONS,\n",
    "    HAND_INDEX_FINGER_CONNECTIONS, HAND_MIDDLE_FINGER_CONNECTIONS,\n",
    "    HAND_RING_FINGER_CONNECTIONS, HAND_PINKY_FINGER_CONNECTIONS\n",
    "])\n",
    "\n",
    "handid2fileid = {a: a + 6 for a in range(21)}\n",
    "\n",
    "#Mapping from joint_id to index_id of array\n",
    "\n",
    "LEFT_HAND_CONNECTIONS_FILE_INDEX = [\n",
    "    (handid2fileid[a], handid2fileid[b])\n",
    "    for (a, b) in HAND_CONNECTIONS\n",
    "]\n",
    "\n",
    "RIGHT_HAND_CONNECTIONS_FILE_INDEX = [\n",
    "    (handid2fileid[a] + 21, handid2fileid[b] + 21)\n",
    "    for (a, b) in HAND_CONNECTIONS\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "197b843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sequence(sequence):\n",
    "    \"\"\"\n",
    "    Input: <List> of keypoints from 37 frames of video -> Shape (37, 48, 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    sequence1 = np.expand_dims(sequence, axis = 0) # Shape: (1, sequence_length, 48, 3)\n",
    "    sequence2 = sequence[1:] -sequence[:-1] # Shape: (sequence_length - 1, 48, 3)\n",
    "    # 3. Bone stream\n",
    "    sequence3 = []\n",
    "\n",
    "    def retrieve_bone_vector(x):\n",
    "        return np.stack([sequence[:, b, :] - sequence[:, a, :] for (a, b) in x], axis=1)\n",
    "    \n",
    "    bone_pose = retrieve_bone_vector(POSE_CONNECTIONS_FILE_INDEX)\n",
    "    bone_left = retrieve_bone_vector(LEFT_HAND_CONNECTIONS_FILE_INDEX)\n",
    "    bone_right = retrieve_bone_vector(RIGHT_HAND_CONNECTIONS_FILE_INDEX)    \n",
    "    sequence3 = np.concatenate([bone_pose, bone_left, bone_right], axis=1) # Shape: (sequence_length, 47, 3)\n",
    "\n",
    "    # 4. Bone motion stream\n",
    "    sequence4 = sequence3[1:] - sequence3[:-1] # Shape: (sequence_length - 1, 47, 3)\n",
    "\n",
    "    return sequence1, np.expand_dims(sequence2, axis = 0), np.expand_dims(sequence3, axis = 0), np.expand_dims(sequence4, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96d859d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\test\\Hand-Tracking-Computer-Control\\best_model\\joint_stream.keras\"\n",
    "model_path2 = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\test\\Hand-Tracking-Computer-Control\\best_model\\joint_motion_stream.keras\"\n",
    "model_path3 = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\test\\Hand-Tracking-Computer-Control\\best_model\\bone_stream.keras\"\n",
    "model_path4 = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\test\\Hand-Tracking-Computer-Control\\best_model\\bone_motion_stream.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7be7c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:421: UserWarning: `build()` was called on layer 'msst__layer_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"joint_stream\": load_model(model_path1, custom_objects={'MSST_Layer': MSST_Layer}),\n",
    "    \"joint_motion_stream\": load_model(model_path2, custom_objects={'MSST_Layer': MSST_Layer}),\n",
    "    \"bone_stream\": load_model(model_path3, custom_objects={'MSST_Layer': MSST_Layer}),\n",
    "    \"bone_motion_stream\": load_model(model_path4, custom_objects={'MSST_Layer': MSST_Layer}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fe1ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 37, 48, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "(1, 18)\n",
      "Swiping Down\n"
     ]
    }
   ],
   "source": [
    "test_case = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\joint_stream\\val\\00030.npy\"\n",
    "test_case = np.load(test_case)\n",
    "test_case  = np.expand_dims(test_case, axis=0)\n",
    "print(test_case.shape)\n",
    "model = models[\"joint_stream\"]\n",
    "pred = model.predict(test_case)\n",
    "print(pred.shape)\n",
    "print(actions[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c90ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "action2index = {a: i for i, a in enumerate(actions)}\n",
    "one_hot_labels = to_categorical(range(len(actions)), num_classes=len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c129bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(sequence):\n",
    "    seqs = cal_sequence(sequence)\n",
    "    preds = np.array([model.predict(s)[0] for model, s in zip(models.values(), seqs)]) #Softmax [0.1, 0.2,...]\n",
    "    ensemble_pred = np.mean(preds, axis=0) #Softmax (ensemble)\n",
    "    return preds + [ensemble_pred] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "461f91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data holders\n",
    "y_true, y_true_encoded = [], []\n",
    "predictions = {k: [] for k in models.keys()}\n",
    "predictions[\"ensemble\"] = []\n",
    "scores = {k: [] for k in models.keys()}\n",
    "scores[\"ensemble\"] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f327fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = r\"C:\\Users\\Admin\\Documents\\2024.2\\CV\\Project\\joint_stream\\val\"\n",
    "\n",
    "for _, row in tqdm(df_filtered.iterrows()):\n",
    "    video_file = os.path.join(val_path, f\"{row['video_id']:05d}.npy\")\n",
    "    if not os.path.exists(video_file):\n",
    "        continue\n",
    "\n",
    "    sequence = np.load(video_file)\n",
    "    preds = predict_sequence(sequence)\n",
    "    \n",
    "    y_true.append(row['label']) # (4780,)\n",
    "    y_true_encoded.append(one_hot_labels[action2index[row['label']]]) # (4780, 18)\n",
    "\n",
    "    for key, pred in zip(list(models.keys()) + [\"ensemble\"], preds):\n",
    "        pred_label = actions[np.argmax(pred)]\n",
    "        predictions[key].append(pred_label) # (5, 4780)\n",
    "        scores[key].append(pred) # (5, 4780, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5a3efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores (5, 4780, 18)\n",
    "# predictions (5, 4780, 1)\n",
    "model_keys = list(scores.keys())[:4]  # ['model_1', 'model_2', 'model_3', 'model_4']\n",
    "\n",
    "arrays = [np.array(scores[k]) for k in model_keys]  # mỗi cái (4780, 18)\n",
    "\n",
    "stacked = np.stack(arrays, axis=0)  \n",
    "\n",
    "avg_softmax = np.mean(stacked, axis=0)\n",
    "\n",
    "scores['ensemble'] = avg_softmax # 4780, 18\n",
    "predictions['ensemble'] = np.argmax(scores['ensemble'], axis = 1)\n",
    "predictions['ensemble'] = [actions[i] for i in predictions['ensemble']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "147a9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "633f5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_true_enc, y_scores):\n",
    "    metrics = {}\n",
    "    for key in y_pred.keys():\n",
    "        \n",
    "        metrics[key] = {\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred[key]),\n",
    "            \"precision\": precision_score(y_true, y_pred[key], average='weighted'),\n",
    "            \"recall\": recall_score(y_true, y_pred[key], average='weighted'),\n",
    "            \"f1\": f1_score(y_true, y_pred[key], average='weighted')\n",
    "        }\n",
    "\n",
    "        if len(y_true_enc) > 0 and len(y_scores[key]) > 0:\n",
    "            try:\n",
    "                auc = roc_auc_score(np.array(y_true_enc), np.array(y_scores[key]), average='weighted', multi_class='ovr')\n",
    "                metrics[key][\"auc\"] = auc\n",
    "            except ValueError as e:\n",
    "                print(f\"AUC error for {key}: {e}\")\n",
    "                metrics[key][\"auc\"] = np.nan\n",
    "        else:\n",
    "            print(f\"AUC skipped for {key} due to empty inputs.\")\n",
    "            metrics[key][\"auc\"] = np.nan\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b107d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(y_true, predictions, y_true_encoded, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b1e0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model Accuracy Precision Recall F1 Score    AUC\n",
      "       Joint Stream   0.8906    0.8920 0.8906   0.8904 0.9952\n",
      "Joint Motion Stream   0.8877    0.8910 0.8877   0.8879 0.9952\n",
      "        Bone Stream   0.8906    0.8913 0.8906   0.8904 0.9952\n",
      " Bone Motion Stream   0.8611    0.8633 0.8611   0.8606 0.9947\n",
      "           Ensemble   0.9044    0.9062 0.9044   0.9043 0.9954\n"
     ]
    }
   ],
   "source": [
    "table_data = []\n",
    "for model_name, metric in metrics.items():\n",
    "    table_data.append([\n",
    "        model_name.replace('_', ' ').title(),\n",
    "        metric['accuracy'],\n",
    "        metric['precision'],\n",
    "        metric['recall'],\n",
    "        metric['f1'],\n",
    "        metric['auc']\n",
    "    ])\n",
    "\n",
    "df_results = pd.DataFrame(table_data, columns=[\n",
    "    \"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\"\n",
    "])\n",
    "\n",
    "df_results[[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\"]] = df_results[\n",
    "    [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\"]\n",
    "].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "\n",
    "print(df_results.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
